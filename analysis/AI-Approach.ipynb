{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from curve_functions import FunctionProvider\n",
    "import sklearn.preprocessing as prep\n",
    "import typing\n",
    "\n",
    "RESULTS_BACKUP_PATH = '/home/mnapravnik/Documents/PhD/Efficiency-of-dragging-gestures/Results_backup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcf6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# first, gather all of the data related to drawn figures\n",
    "def get_drawn_figures(test:int=0):\n",
    "    \n",
    "    path = f'{RESULTS_BACKUP_PATH}{test}'\n",
    "    columns = [\n",
    "        'Username',\n",
    "        'TestIndex',\n",
    "        'Device',\n",
    "        'FigureID',\n",
    "        'Projection',\n",
    "        'ProjectionName',\n",
    "        'Order',\n",
    "        'Fullpath',\n",
    "        'Npoints'\n",
    "    ]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for user_direntry in os.scandir(path):\n",
    "        # each directory is named after the user participant\n",
    "        _username = user_direntry.name\n",
    "        _username = re.sub(' ', '_', _username)\n",
    "        \n",
    "        for device_direntry in os.scandir(user_direntry.path):\n",
    "            _device = device_direntry.name\n",
    "            _device = re.sub(' ', '_', _device)\n",
    "                \n",
    "            for drawing_direntry in os.scandir(device_direntry.path):\n",
    "                _only_numbers_and_underscore = re.sub('[^0-9,_]', '', drawing_direntry.name)\n",
    "                _figureid, _projection, _order = _only_numbers_and_underscore.split('_')\n",
    "                _figureid = int(_figureid)\n",
    "                _projection = int(_projection)\n",
    "                _order = int(_order)\n",
    "                \n",
    "                # check how many drawn points there are\n",
    "                npoints = 0\n",
    "                with open(drawing_direntry.path) as file:\n",
    "                    npoints = len(file.readlines())\n",
    "                \n",
    "                # there seems to be a bug with polar projections\n",
    "                # where figures in projection 2 are named as projection 3\n",
    "                # and that happens only when\n",
    "                # figureid is 0, so just fix it here, on-the-go\n",
    "                if (_figureid == 0):\n",
    "                    if(_projection == 2):\n",
    "                        _projection = 3\n",
    "                    elif(_projection == 3):\n",
    "                        _projection = 2\n",
    "                _projection_name = 'Cartesian' if _projection in [0, 1] else 'Polar'\n",
    "                    \n",
    "                \n",
    "                # append the row to the end of the dataframe\n",
    "                df.loc[len(df)] = [\n",
    "                    _username,\n",
    "                    test,\n",
    "                    _device,\n",
    "                    _figureid,\n",
    "                    _projection,\n",
    "                    _projection_name,\n",
    "                    _order,\n",
    "                    drawing_direntry.path,\n",
    "                    npoints\n",
    "                ]\n",
    "#     df.set_index(['Username'], inplace=True)\n",
    "    return df\n",
    "    \n",
    "df = get_drawn_figures(0)\n",
    "df = pd.concat([df, get_drawn_figures(1)], ignore_index=True)\n",
    "\n",
    "display(df)\n",
    "display(df.Username.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f9731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_drawn_coordinates(df_entry, scale:bool=False):\n",
    "    _drawingx, _drawingy = [], []\n",
    "    with open(df_entry.Fullpath) as file:\n",
    "        for line in file:\n",
    "            pointx, pointy = line.split()\n",
    "            pointx = float(pointx)\n",
    "            pointy = float(pointy)\n",
    "            _drawingx.append(pointx)\n",
    "            _drawingy.append(pointy)\n",
    "    return _drawingx, _drawingy\n",
    "\n",
    "def scale_coordinates(df_entry, x, y):\n",
    "    from display_properties import CARTESIAN_PLOT_LIMITS, POLAR_PLOT_LIMITS\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    if df_entry.Projection in [0,1]:\n",
    "        # Cartesian plot\n",
    "        y = (y - CARTESIAN_PLOT_LIMITS['y'][0]) / CARTESIAN_PLOT_LIMITS['y'][1]\n",
    "        x = (x - CARTESIAN_PLOT_LIMITS['x'][0]) / CARTESIAN_PLOT_LIMITS['x'][1]\n",
    "    else:\n",
    "        # Polar plot\n",
    "        # due to scaling, polar plots will look a bit idiotic\n",
    "        y = (y - POLAR_PLOT_LIMITS['y'][0]) / POLAR_PLOT_LIMITS['y'][1]\n",
    "        x = (x - POLAR_PLOT_LIMITS['x'][0]) / POLAR_PLOT_LIMITS['x'][1]\n",
    "    return x, y\n",
    "\n",
    "def unscale_coordinates(x, y, projection):\n",
    "    from display_properties import CARTESIAN_PLOT_LIMITS, POLAR_PLOT_LIMITS\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    if projection in [0,1]:\n",
    "        # Cartesian plot\n",
    "        y = y * CARTESIAN_PLOT_LIMITS['y'][1] + CARTESIAN_PLOT_LIMITS['y'][0]\n",
    "        x = y * CARTESIAN_PLOT_LIMITS['x'][1] + CARTESIAN_PLOT_LIMITS['x'][0]\n",
    "    else:\n",
    "        # Polar plot\n",
    "        y = y * POLAR_PLOT_LIMITS['y'][1] + POLAR_PLOT_LIMITS['y'][0]\n",
    "        x = y * POLAR_PLOT_LIMITS['x'][1] + POLAR_PLOT_LIMITS['x'][0]\n",
    "    return x, y \n",
    "    \n",
    "\n",
    "def get_real_coordinates(df_entry, x):\n",
    "    fp = FunctionProvider()\n",
    "    difficulty = int(df_entry.FigureID / 2)\n",
    "    task = int(df_entry.FigureID % 2)\n",
    "    func_y = fp.provide_function_y(difficulty, task, x, df_entry.Projection)\n",
    "    return x, func_y\n",
    "\n",
    "# Inspect drawn vs. original data\n",
    "def plot_function_and_drawing(df_entry):\n",
    "    _drawingx, _drawingy = get_drawn_coordinates(df_entry)\n",
    "    \n",
    "    _, func_y = get_real_coordinates(df_entry, _drawingx)\n",
    "#     _drawingx, _drawingy = scale_coordinates(df_entry, _drawingx, _drawingy)\n",
    "#     _, func_y = scale_coordinates(df_entry, _drawingx, func_y)\n",
    "    \n",
    "    if df_entry.ProjectionName == 'Cartesian':\n",
    "        # cartesian projection\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        # polar projection\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "    ax = fig.gca()\n",
    "    ax.plot(_drawingx, func_y, label='Original')\n",
    "    ax.plot(_drawingx, _drawingy, label='Drawn', color='gray')\n",
    "    ax.set_title(\n",
    "        f'FigureID: {df_entry.FigureID}, Projection: {df_entry.Projection}'\n",
    "    )\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "entry = df.query('Projection == 3 and FigureID == 2').iloc[8]\n",
    "print('Entry ID:', entry.name)\n",
    "plot_function_and_drawing(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeecae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "columncnt = 5000\n",
    "from display_properties import X_RANGE\n",
    "# this is the X RANGE for ALLLLL (!!!) OF THE functions\n",
    "# both the drawn and the generated (original) functions\n",
    "X_FOR_ALL_FUNC = np.linspace(X_RANGE['start'], X_RANGE['end'], columncnt)\n",
    "\n",
    "def prepare_points(df, columncnt:int):\n",
    "    \"\"\"\n",
    "    This accepts the original dataframe as input\n",
    "    and returns the points encoded and ready for training.\n",
    "    All coordinates are scaled between [0, 1]\n",
    "    and scaled to be the same length (columncnt is the length)\n",
    "    \n",
    "    Returns three values:\n",
    "    - the value on the X axis\n",
    "    - the value drawn by the user\n",
    "    - the real value of the function\n",
    "    \n",
    "    \"\"\"\n",
    "    def convert_to_same_size(columncnt:int, x, y):\n",
    "        resultx = np.zeros(columncnt)\n",
    "        resulty = np.zeros(columncnt)\n",
    "        if(len(x) < columncnt):\n",
    "            # this has the effect of zero-padding\n",
    "            # because were adding the drawings to an array of zeros\n",
    "            resultx[:len(x)] = x\n",
    "            resulty[:len(y)] = y\n",
    "        else:\n",
    "            # otherwise crop the drawing\n",
    "            resultx = x[:columncnt]\n",
    "            resulty = y[:columncnt]\n",
    "        return resultx, resulty\n",
    "    \n",
    "    x = []\n",
    "    drawn_y = []\n",
    "    real_y = []\n",
    "    for index in df.index:\n",
    "        entry = df.loc[index]\n",
    "        # first, get the drawn coordinates\n",
    "        _drawingx, _drawingy = get_drawn_coordinates(entry)\n",
    "        tmp1, tmp2 = _drawingx.copy(), _drawingy.copy()\n",
    "        \n",
    "        # now, get the real function coordinates\n",
    "        func_x = X_FOR_ALL_FUNC\n",
    "        _, func_y = get_real_coordinates(entry, func_x)\n",
    "        \n",
    "        # interpolate the drawn curves so they always have the same x values\n",
    "        if entry.ProjectionName == 'Cartesian':\n",
    "            _drawingy = np.interp(func_x, _drawingx, _drawingy)\n",
    "        else:\n",
    "            # polar function have a period of 2pi so interpolate them as such\n",
    "            _drawingy = np.interp(func_x, _drawingx, _drawingy, period=360)\n",
    "        _drawingx = func_x\n",
    "        \n",
    "        # test to see if the interpolated function still looks like the original\n",
    "#         if entry.ProjectionName == 'Cartesian':\n",
    "#             # cartesian projection\n",
    "#             fig, ax = plt.subplots()\n",
    "#         else:\n",
    "#             # polar projection\n",
    "#             fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "#         ax.plot(func_x, func_y, label='original func')\n",
    "#         ax.plot(tmp1, tmp2, label='original drawn')\n",
    "#         ax.plot(_drawingx, _drawingy, label='interp')\n",
    "#         ax.legend()\n",
    "#         plt.show()\n",
    "                \n",
    "        # scale coords between 0 and 1\n",
    "        _, func_y = scale_coordinates(entry, _drawingx, func_y)\n",
    "        _drawingx, _drawingy = scale_coordinates(entry, _drawingx, _drawingy)\n",
    "#         # add zero padding where necessary\n",
    "#         _, func_y = convert_to_same_size(columncnt, x=_drawingx, y=func_y)\n",
    "#         _drawingx, _drawingy = convert_to_same_size(columncnt, x=_drawingx, y=_drawingy)\n",
    "        \n",
    "        x.append(_drawingx)\n",
    "        drawn_y.append(_drawingy)\n",
    "        real_y.append(func_y)\n",
    "        \n",
    "    x = np.array(x)\n",
    "    drawn_y = np.array(drawn_y)\n",
    "    real_y = np.array(real_y)\n",
    "    \n",
    "    return x, drawn_y, real_y\n",
    "\n",
    "def prepare_dataset_for_user_classification(df, columncnt:int):\n",
    "    x, drawn_y, real_y = prepare_points(df, columncnt)\n",
    "    y = np.abs(drawn_y - real_y)\n",
    "    \n",
    "    # now prepare the rest: i.e. the device used, the projection and the usernames\n",
    "    proj_encoder = prep.LabelBinarizer()\n",
    "    proj_encoded = proj_encoder.fit_transform(df.ProjectionName)\n",
    "    user_encoder = prep.LabelBinarizer()\n",
    "    user_encoded = user_encoder.fit_transform(df.Username)\n",
    "    # the devices only have two values: Mouse & Graphic tablet\n",
    "    # so use Label Encoder instead\n",
    "    device_encoder = prep.LabelBinarizer()\n",
    "    device_encoded = device_encoder.fit_transform(df.Device)\n",
    "    \n",
    "    device_encoded = np.array(device_encoded, dtype='int16')\n",
    "    user_encoded = np.array(user_encoded, dtype='int16')\n",
    "    proj_encoded = np.array(proj_encoded, dtype='int16')\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    Entry = namedtuple('Entry', ['encoded', 'encoder', 'name'])\n",
    "    entries_to_add_to_df: typing.List[Entry] = [\n",
    "        Entry(proj_encoded, proj_encoder, 'Projection'),\n",
    "        Entry(user_encoded, user_encoder, 'Username'),\n",
    "        Entry(device_encoded, device_encoder, 'Device'),\n",
    "#         Entry(x, None, 'Xcoord'),\n",
    "        Entry(drawn_y, None, 'drawnY'),\n",
    "        Entry(real_y, None, 'realY'),\n",
    "#         Entry(y, None, 'YDiff')\n",
    "    ]\n",
    "    \n",
    "    # now, join everything into a single dataframe\n",
    "    # first, get column names to use\n",
    "    columns = []\n",
    "    for encoded, encoder, name in entries_to_add_to_df:\n",
    "        col_names = []\n",
    "        for _idx in range(np.shape(encoded)[1]):\n",
    "            _tmp = _idx\n",
    "            if(encoder is not None):\n",
    "                _tmp = encoder.classes_[_idx]\n",
    "            col_names.append(f'{name}_{_tmp}')\n",
    "        \n",
    "        columns = columns + col_names\n",
    "    # horizontally stack all of the encoded values\n",
    "    data = np.hstack([entry.encoded for entry in entries_to_add_to_df])\n",
    "    df = pd.DataFrame(\n",
    "        columns=columns,\n",
    "        data=data,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_to_use = df.copy()\n",
    "# df_to_use = df.copy()\n",
    "display(df_to_use)\n",
    "encoded_df = prepare_dataset_for_user_classification(\n",
    "    df_to_use,\n",
    "    columncnt=5000\n",
    ")\n",
    "display(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encoded_df[df_to_use.TestIndex == 0]\n",
    "test_df = encoded_df[df_to_use.TestIndex == 1]\n",
    "\n",
    "train_dfY = train_df.filter(regex='Username_*')\n",
    "train_dfX = train_df.drop(train_dfY.columns, axis=1)\n",
    "\n",
    "test_dfY = test_df.filter(regex='Username_*')\n",
    "test_dfX = test_df.drop(test_dfY.columns, axis=1)\n",
    "\n",
    "display(train_dfX)\n",
    "display(test_dfX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684ceaf",
   "metadata": {},
   "source": [
    "# Classification model in PyTorch\n",
    "https://stackabuse.com/introduction-to-pytorch-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432aa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# limit CPU usage\n",
    "torch.set_num_threads(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, hidden_layer_sizes:typing.List[int], input_size:int, output_size=int, dropout=0.3):\n",
    "        super().__init__()\n",
    "        _all_layers = []\n",
    "        for _size in hidden_layer_sizes:\n",
    "            _all_layers.append(nn.Linear(input_size, _size))\n",
    "            _all_layers.append(nn.ReLU(inplace=True))\n",
    "            _all_layers.append(nn.BatchNorm1d(_size))\n",
    "            # apply dropout if specified so\n",
    "            if dropout > 0:\n",
    "                _all_layers.append(nn.Dropout(dropout))\n",
    "            # update the input size of the following layer\n",
    "            input_size = _size\n",
    "        # this is the output layer\n",
    "        _all_layers.append(nn.Linear(in_features=hidden_layer_sizes[-1], out_features=output_size))\n",
    "        # apply another activation function to the output layer, so that the output is scaled\n",
    "#         _all_layers.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        # finally, create a model that has all these layers\n",
    "        # aligned in a sequence\n",
    "        # this means the layers will be called/processed one after the other\n",
    "        self.layers = nn.Sequential(*_all_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x[0:10])\n",
    "        return self.layers(x)\n",
    "\n",
    "# convert the pandas df into torch tensor\n",
    "torch_train_dfX = torch.tensor(np.array(train_dfX, dtype='float32'))\n",
    "torch_train_dfY = torch.tensor(np.array(train_dfY, dtype='float32'))\n",
    "torch_test_dfX = torch.tensor(np.array(test_dfX, dtype='float32'))\n",
    "torch_test_dfY = torch.tensor(np.array(test_dfY, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe614b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = torch_train_dfX.shape[1]\n",
    "output_size = torch_train_dfY.shape[1]\n",
    "display(input_size, output_size)\n",
    "model = ClassificationModel([2**10, 2**8, 2**6], input_size=input_size, output_size=output_size, dropout=0.5)\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "epochs = 15\n",
    "aggregated_losses = []\n",
    "\n",
    "for _epoch_idx in range(epochs):\n",
    "    y_pred = model(torch_train_dfX)\n",
    "    loss_in_this_epoch = loss_function(y_pred, torch_train_dfY)\n",
    "    aggregated_losses.append(loss_in_this_epoch)\n",
    "    \n",
    "    _end = '\\r'\n",
    "    if (_epoch_idx + 1) % 10 == 0:\n",
    "        _end = '\\n'\n",
    "    print(f'Epoch {_epoch_idx+1:4} ===> loss {loss_in_this_epoch.item():10.8f}', end=_end)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # propagate the calculated loss backward through the network\n",
    "    loss_in_this_epoch.backward()\n",
    "    # update the weights in the network\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d02c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(epochs), [loss.detach().numpy() for loss in aggregated_losses])\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    model.eval()\n",
    "    y_val = model(torch_test_dfX)\n",
    "    loss = loss_function(y_val, torch_test_dfY)\n",
    "    \n",
    "    _cnt = 10\n",
    "    argmax_y_val = np.argmax(y_val, axis=1)\n",
    "    argmax_y_true = np.argmax(torch_test_dfY, axis=1)\n",
    "    print(f'Loss on test data: {loss}')\n",
    "    print(argmax_y_val[:_cnt])\n",
    "    print(argmax_y_true[:_cnt])\n",
    "    print(y_val[:_cnt])\n",
    "    display(test_dfY)\n",
    "    \n",
    "    print(classification_report(argmax_y_true, argmax_y_val))\n",
    "    print(confusion_matrix(argmax_y_true, argmax_y_val))\n",
    "    \n",
    "    for i in range(100):\n",
    "        real_user_index = argmax_y_true[i]\n",
    "        predicted_user_index = argmax_y_val[i]\n",
    "        if(real_user_index != predicted_user_index):\n",
    "            # plot how the predicted and the real user\n",
    "            # drew this figure\n",
    "            _df_entry = df_to_use.query('TestIndex == 1').iloc[i]\n",
    "            x_real, y_real = get_drawn_coordinates(_df_entry)\n",
    "            real_user_name = _df_entry.Username\n",
    "            \n",
    "            predicted_user_name = list(test_dfY.columns)[predicted_user_index]\n",
    "            predicted_user_name = re.sub('Username_', '', predicted_user_name)\n",
    "            _predicted_user_df_entry = df.query(\n",
    "                f'Username == \"{predicted_user_name}\" and Device == \"{_df_entry.Device}\"' +\n",
    "                f' and FigureID == {_df_entry.FigureID} and Projection == {_df_entry.Projection}'\n",
    "            ).sample(1).iloc[0]\n",
    "            x_pred, y_pred = get_drawn_coordinates(_predicted_user_df_entry)\n",
    "            \n",
    "            if _df_entry.ProjectionName == 'Cartesian':\n",
    "                # cartesian projection\n",
    "                fig, ax = plt.subplots()\n",
    "            else:\n",
    "                # polar projection\n",
    "                fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "            ax = fig.gca()\n",
    "            ax.plot(x_real, y_real, label=f'Real user {real_user_name}')\n",
    "            ax.plot(x_pred, y_pred, label=f'Pred user {predicted_user_name}')\n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977ec2f",
   "metadata": {},
   "source": [
    "# Autoencoder to generate new drawings\n",
    "https://debuggercafe.com/getting-started-with-variational-autoencoder-using-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEModel(nn.Module):\n",
    "    def __init__(self, hidden_layer_sizes:typing.List[int], in_size:int, out_size:int, dropout:float=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        def get_layers(_layer_sizes:typing.List[int], input_size:int):\n",
    "            _layers = []\n",
    "            for i in _layer_sizes:\n",
    "                _layers.append(nn.Linear(in_features=input_size, out_features=i))\n",
    "                _layers.append(nn.LeakyReLU(inplace=True))\n",
    "                _layers.append(nn.BatchNorm1d(i))\n",
    "                if dropout > 0:\n",
    "                    _layers.append(nn.Dropout(dropout))\n",
    "                # update the input size of the following layer\n",
    "                input_size = i\n",
    "            return _layers\n",
    "            \n",
    "        # encoder part of the network\n",
    "        _encoder_layers = get_layers(hidden_layer_sizes, input_size=in_size)\n",
    "        \n",
    "        # we want the bottleneck to be divisible by two\n",
    "        # so this right here finds the power of 2 which is the closest\n",
    "        # to the last layer\n",
    "        _bottleneck_pow = int(np.log2(hidden_layer_sizes[-1]))\n",
    "        self.bottleneck_size = 2 ** (_bottleneck_pow - 1)\n",
    "        \n",
    "        # decoder part of network\n",
    "        _reversed_lyrs = list(reversed(hidden_layer_sizes))\n",
    "        _decoder_layers = get_layers(_reversed_lyrs, input_size=self.bottleneck_size)\n",
    "        _decoder_layers.append(nn.Linear(in_features=_reversed_lyrs[-1], out_features=out_size))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*_encoder_layers)\n",
    "        self.decoder = nn.Sequential(*_decoder_layers)\n",
    "    \n",
    "    def reparametrize(self, mu: typing.Iterable[float], log_var: typing.Iterable[float]):\n",
    "        # mu = mean from the encoder latent space\n",
    "        # log_var = log variance of the encoder latent space\n",
    "        # these two are tensor arrays\n",
    "        \n",
    "        # standard deviation --> get form log variance\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        \n",
    "        # this will return an array of values from the normal distributions\n",
    "        # where mean is 0 and var is 1\n",
    "        # i.e. this will be an array of a normalized dist with the same\n",
    "        # shape as the array 'std'\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # shift the distribution to 'mu' mean and 'log_var' variance\n",
    "        sample = mu + (eps * std)\n",
    "        return sample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 2, self.bottleneck_size)\n",
    "        # x as this point is NOT the latent representation\n",
    "        \n",
    "        mu = x[:, 0, :]\n",
    "        log_var = x[:, 1, :]\n",
    "        def numnan(arr):\n",
    "            arr = arr.detach().numpy()\n",
    "            return np.sum(np.isnan(arr))\n",
    "        \n",
    "        \n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        # now we have the latent representation\n",
    "        \n",
    "        x = self.decoder(z)\n",
    "        reconstruction = torch.sigmoid(x)\n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da776129",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset_for_vae(df, columncnt):\n",
    "    x, drawn_y, real_y = prepare_points(df, columncnt=columncnt)\n",
    "    x = np.array(x, dtype='float32')\n",
    "    drawn_y = np.array(drawn_y, dtype='float32')\n",
    "    real_y = np.array(real_y, dtype='float32')\n",
    "    \n",
    "    # input should contain the value on the x axis and the\n",
    "    # original (real) value\n",
    "#     X = np.hstack([x, real_y])\n",
    "    X = drawn_y\n",
    "    \n",
    "    # the output should contain the drawn value\n",
    "#     Y = np.hstack([x, drawn_y])\n",
    "    Y = real_y\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def perform_train(trainx, trainy, testx, testy):    \n",
    "    model = VAEModel([2**13, 2**12, 2**11], in_size=trainx.shape[1], out_size=trainy.shape[1],  dropout=0)\n",
    "    display(model)\n",
    "    \n",
    "    lr = 0.001\n",
    "    batch_size = 64\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    bce = nn.BCELoss(reduction='mean')\n",
    "    \n",
    "    # dataloaders with batch sizes\n",
    "    trainx_loader = torch.utils.data.DataLoader(torch.tensor(trainx), batch_size=batch_size, shuffle=False)\n",
    "    trainy_loader = torch.utils.data.DataLoader(torch.tensor(trainy), batch_size=batch_size, shuffle=False)\n",
    "    testx_loader = torch.utils.data.DataLoader(torch.tensor(testx), batch_size=batch_size, shuffle=False)\n",
    "    testy_loader = torch.utils.data.DataLoader(torch.tensor(testy), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    def loss_function(bce_loss, mu, log_var):\n",
    "        BCE = bce_loss\n",
    "        KLD = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp())\n",
    "        # the final loss is binary cross entropy + kullback leibler divergence\n",
    "        return BCE + KLD\n",
    "    \n",
    "    def fit(model, xdataloader, ydataloader, validation:bool=False):\n",
    "        i = 0\n",
    "        total_epoch_loss = 0.0\n",
    "        for x, y in zip(xdataloader, ydataloader):\n",
    "            if validation is False:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            reconstruction, mu, log_var = model(x)\n",
    "            bce_loss = bce(reconstruction, y)\n",
    "            loss = loss_function(bce_loss, mu, log_var)\n",
    "            total_epoch_loss += loss\n",
    "                            \n",
    "#             if i == 0:\n",
    "#                 fig = plt.figure()\n",
    "#                 ax = fig.gca()\n",
    "#                 import random\n",
    "#                 _ind = random.randint(0, len(x)-1)\n",
    "#                 tmp = x[_ind]\n",
    "#                 tmp2 = y[_ind]\n",
    "#                 tmp3 = reconstruction[_ind]\n",
    "#                 tmp3 = [t.detach().numpy() for t in tmp3]\n",
    "#                 ax.plot(X_FOR_ALL_FUNC, tmp)\n",
    "#                 ax.plot(X_FOR_ALL_FUNC, tmp2)\n",
    "#                 ax.plot(X_FOR_ALL_FUNC, tmp3)\n",
    "#                 ax.set_title(f'index {_ind}')\n",
    "#                 plt.show()\n",
    "#                 i += 1\n",
    "\n",
    "            if validation is False:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return total_epoch_loss\n",
    "\n",
    "    epochs = 50\n",
    "    train_losses, val_losses = [], []\n",
    "    for _epoch_idx in range(epochs):\n",
    "        # switch model to training mode\n",
    "        model.train()\n",
    "        train_epoch_loss = fit(model, trainx_loader, trainy_loader, False)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        # and now val mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_epoch_loss = fit(model, testx_loader, testy_loader, True)\n",
    "            val_losses.append(val_epoch_loss)\n",
    "        \n",
    "        print(f'Epoch: {_epoch_idx+1:5} / {epochs};',\n",
    "              f' train loss: {train_epoch_loss:.5f}, val loss: {val_epoch_loss:.5f}')\n",
    "    \n",
    "    def plot_training_stats():\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "        ax.plot(range(epochs), [loss.detach().numpy() for loss in train_losses], label='Train')\n",
    "        ax.plot(range(epochs), [loss.detach().numpy() for loss in val_losses], label='Val')\n",
    "        ax.set_title('Losses')\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    plot_training_stats()\n",
    "    return model\n",
    "\n",
    "def do_everything(columncnt):\n",
    "    trainx, trainy = prepare_dataset_for_vae(df.query('TestIndex == 0'), columncnt)\n",
    "    testx, testy   = prepare_dataset_for_vae(df.query('TestIndex == 1'), columncnt)\n",
    "    model = perform_train(trainx, trainy, testx, testy)\n",
    "\n",
    "    return model, (trainx, trainy, testx, testy)\n",
    "\n",
    "columncnt = len(X_FOR_ALL_FUNC)\n",
    "vae_model, datasets = do_everything(columncnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528cbdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_prediction(testx, testy, model, columncnt):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    import random\n",
    "    _ind = random.randint(0, len(testx))\n",
    "    real_func_x = X_FOR_ALL_FUNC\n",
    "    real_func_y = testx[_ind]\n",
    "    ax.plot(real_func_x, real_func_y, label='Original')\n",
    "    \n",
    "    drawn_func_x = X_FOR_ALL_FUNC\n",
    "    drawn_func_y = testy[_ind]\n",
    "    ax.plot(drawn_func_x, drawn_func_y, label='Drawn')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted, _, _ = model(torch.tensor(testx))\n",
    "        \n",
    "#         pred_func_x = predicted[_ind, :columncnt]\n",
    "        pred_func_x = X_FOR_ALL_FUNC\n",
    "        pred_func_y = predicted[_ind]\n",
    "        ax.plot(pred_func_x, pred_func_y, label='Predicted')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "draw_prediction(datasets[2], datasets[3], vae_model, columncnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdb0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
